# rag/embed_documents.py
"""
merged_all.jsonl ì „ì²´ë¥¼ ì„ë² ë”©í•´ì„œ
embedded_all.jsonl ë¡œ ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
(ì´ë¯¸ ì¼ë¶€ ì„ë² ë”©ëœ ê²½ìš°, ì´ì–´ì„œ ì¬ê°œ)
"""

import json
import time
from pathlib import Path

from dotenv import load_dotenv
from openai import OpenAI, RateLimitError, APIError, PermissionDeniedError


# =========================
# ê²½ë¡œ & í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent          # .../ai_service/rag
DATA_DIR = BASE_DIR / "data"
INPUT_PATH = DATA_DIR / "merged_all.jsonl"
OUTPUT_PATH = DATA_DIR / "embedded_all.jsonl"       # âœ… ì „ì²´ìš© ì¶œë ¥ íŒŒì¼

# .env ë¡œë“œ (ë£¨íŠ¸ì— ìˆë‹¤ê³  ê°€ì •: .../ai_service/.env)
PROJECT_ROOT = BASE_DIR  # rag ë°”ë¡œ ìœ„ê°€ ai_service ë‹ˆê¹Œ ì´ëŒ€ë¡œ ì¨ë„ ë¨
env_path = PROJECT_ROOT / ".env"
if env_path.exists():
    load_dotenv(env_path)

# OpenAI í´ë¼ì´ì–¸íŠ¸ (í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEY ì‚¬ìš©)
client = OpenAI()

EMBED_MODEL = "text-embedding-3-large"

# MAX_DOCS = None ì´ë©´ ì „ì²´ ì²˜ë¦¬
MAX_DOCS = None   # âœ… ì „ì²´ ë°ì´í„° ëŒë¦¬ë ¤ë©´ None, í…ŒìŠ¤íŠ¸ëŠ” 100 ì´ëŸ° ì‹ìœ¼ë¡œ


def build_text_to_embed(doc: dict) -> str:
    """
    í•œ ë¬¸ì„œ(dict)ì—ì„œ ì„ë² ë”©ì— ì“¸ í…ìŠ¤íŠ¸ë¥¼ í•©ì³ì„œ ë§Œë“ ë‹¤.
    ì—†ëŠ” í•„ë“œëŠ” ë¬´ì‹œí•˜ê³ , ìˆëŠ” ê²ƒë§Œ ì´ì–´ ë¶™ì„.
    """
    parts = []

    for key in [
        "title",
        "content",
        "drug_name_kor",
        "drug_name_eng",
        "disease_name_kor",
        "disease_name_eng",
        "excipients",
        "topic",
        "departments",
        "entity_1",
        "entity_2",
    ]:
        value = doc.get(key)
        if value:
            parts.append(str(value))

    # í˜¹ì‹œ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ idë¼ë„ ë„£ì–´ì„œ ë¹ˆ ë¬¸ìì—´ì€ í”¼í•¨
    if not parts:
        parts.append(str(doc.get("id", "")))

    return "\n".join(parts)


def safe_embed_text(text: str):
    """
    OpenAI ì„ë² ë”© í˜¸ì¶œ + ê°„ë‹¨í•œ ì¬ì‹œë„ ë¡œì§.
    PermissionDenied(403, ì¿¼í„°/ê¶Œí•œ ë¬¸ì œ)ëŠ” ë°”ë¡œ raise.
    """
    max_retries = 5

    for attempt in range(1, max_retries + 1):
        try:
            resp = client.embeddings.create(
                model=EMBED_MODEL,
                input=text,
            )
            return resp.data[0].embedding

        except RateLimitError as e:
            wait = 5 * attempt
            print(f"[RateLimit] {attempt}/{max_retries}íšŒì§¸, {wait}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„: {e}")
            time.sleep(wait)

        except PermissionDeniedError as e:
            # ë³´í†µ ì¿¼í„°/ê¶Œí•œ ë¬¸ì œë¼ ì¬ì‹œë„í•´ë„ ì˜ë¯¸ê°€ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŒ
            print("\n[PermissionDenied] 403 ì˜¤ë¥˜ ë°œìƒ (ë³´í†µ ì¿¼í„°/ê¶Œí•œ ë¬¸ì œ)")
            print("â¡ OpenAI ëŒ€ì‹œë³´ë“œì—ì„œ ì‚¬ìš©ëŸ‰/ì œí•œì„ ë¨¼ì € í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")
            raise

        except APIError as e:
            # ì¼ì‹œì ì¸ ì„œë²„ ì—ëŸ¬ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ëª‡ ë²ˆ ì¬ì‹œë„
            wait = 5 * attempt
            print(f"[APIError] {attempt}/{max_retries}íšŒì§¸, {wait}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„: {e}")
            time.sleep(wait)

    raise RuntimeError("ì„ë² ë”© ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")


def count_already_processed() -> int:
    """
    OUTPUT_PATH(embedded_all.jsonl)ì— ì´ë¯¸ ì €ì¥ëœ ë¼ì¸ ìˆ˜ = ì™„ë£Œëœ ë¬¸ì„œ ìˆ˜
    """
    if not OUTPUT_PATH.exists():
        return 0

    count = 0
    with OUTPUT_PATH.open("r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                count += 1
    return count


def main():
    if not INPUT_PATH.exists():
        raise FileNotFoundError(f"ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_PATH}")

    already = count_already_processed()

    print(f"ğŸ“„ ì…ë ¥ íŒŒì¼: {INPUT_PATH}")
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {OUTPUT_PATH}")
    print(f"âœ… ì´ë¯¸ ì„ë² ë”© ì™„ë£Œëœ ë¬¸ì„œ ìˆ˜: {already}ê°œ")
    print(f"ğŸ”¢ ì´ë²ˆ ì‹¤í–‰ì—ì„œ ì²˜ë¦¬í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜: {MAX_DOCS if MAX_DOCS is not None else 'ì œí•œ ì—†ìŒ'}")

    # MAX_DOCSê°€ ì„¤ì •ëœ ê²½ìš°, ì „ì²´ ì¤‘ ì–´ë””ê¹Œì§€ í• ì§€ ê³„ì‚°
    if MAX_DOCS is not None:
        target_total = already + MAX_DOCS
    else:
        target_total = None  # ëê¹Œì§€

    processed_new = 0

    # ì…ë ¥ì€ ì²˜ìŒë¶€í„° ì½ë˜, already ê°œìˆ˜ë§Œí¼ì€ ê±´ë„ˆë›´ ë’¤ë¶€í„° ì²˜ë¦¬
    with INPUT_PATH.open("r", encoding="utf-8") as f_in, \
         OUTPUT_PATH.open("a", encoding="utf-8") as f_out:   # ğŸ”¥ append ëª¨ë“œ!

        for idx, line in enumerate(f_in):
            # ì´ë¯¸ ëë‚œ ë¶€ë¶„ì€ ìŠ¤í‚µ
            if idx < already:
                continue

            # MAX_DOCS ì œí•œì´ ìˆìœ¼ë©´ ê±°ê¸°ê¹Œì§€ë§Œ
            if target_total is not None and idx >= target_total:
                break

            line = line.strip()
            if not line:
                continue

            doc = json.loads(line)

            text = build_text_to_embed(doc)
            print(f"[{idx+1}] ì„ë² ë”© ìƒì„± ì¤‘... (ê¸¸ì´ {len(text)} ê¸€ì)")

            embedding = safe_embed_text(text)
            doc["embedding"] = embedding  # ë²¡í„° í•„ë“œ ì¶”ê°€

            # ìƒˆ JSONLë¡œ ì €ì¥ (append)
            f_out.write(json.dumps(doc, ensure_ascii=False) + "\n")
            processed_new += 1

    print(f"ğŸ‰ ì´ë²ˆ ì‹¤í–‰ì—ì„œ ìƒˆë¡œ ì„ë² ë”©í•œ ë¬¸ì„œ ìˆ˜: {processed_new}ê°œ")
    print(f"ğŸ“¦ ì´ ì„ë² ë”© ì™„ë£Œ ë¬¸ì„œ ìˆ˜ (ì˜ˆìƒ): {already + processed_new}ê°œ")


if __name__ == "__main__":
    main()
