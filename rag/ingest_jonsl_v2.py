# rag/ingest_jsonl.py
import json
from pathlib import Path
from llm.opensearch_client import get_opensearch_client

INDEX_NAME = "medinote_v3"

BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

# âœ… ì „ì²´ ì„ë² ë”© ê²°ê³¼ íŒŒì¼
INPUT_PATH = DATA_DIR / "embedded_all.jsonl"

# í•œ ë²ˆì— bulkë¡œ ë³´ë‚¼ ë¬¸ì„œ ê°œìˆ˜
BATCH_SIZE = 500  # 500~1000 ì„ ì´ë©´ ì ë‹¹


def bulk_ingest():
    client = get_opensearch_client()

    print(f"ğŸ“„ ì…ë ¥ íŒŒì¼: {INPUT_PATH}")

    if not INPUT_PATH.exists():
        raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {INPUT_PATH}")

    with INPUT_PATH.open("r", encoding="utf-8") as f:
        batch_actions = []
        count = 0
        batch_count = 0

        for line in f:
            line = line.strip()
            if not line:
                continue

            doc = json.loads(line)

            # ì„œë²„ë¦¬ìŠ¤: _id ì‚¬ìš© ê¸ˆì§€. ê·¸ëƒ¥ indexë§Œ.
            action = {
                "index": {
                    "_index": INDEX_NAME
                }
            }

            batch_actions.append(json.dumps(action))
            batch_actions.append(json.dumps(doc, ensure_ascii=False))
            count += 1

            # ë°°ì¹˜ ì‚¬ì´ì¦ˆì— ë„ë‹¬í•˜ë©´ í•œë²ˆ ì „ì†¡
            if len(batch_actions) >= BATCH_SIZE * 2:
                batch_count += 1
                print(f"ğŸš€ ë°°ì¹˜ {batch_count} ì—…ë¡œë“œ ì¤‘... (ëˆ„ì  {count}ê°œ ë¬¸ì„œ)")

                payload = "\n".join(batch_actions) + "\n"

                try:
                    resp = client.transport.perform_request(
                        method="POST",
                        url=f"/{INDEX_NAME}/_bulk",
                        body=payload,
                        headers={"Content-Type": "application/json"}
                    )
                except Exception as e:
                    # HTTP ë ˆë²¨ ì˜ˆì™¸
                    print(f"âŒ ë°°ì¹˜ {batch_count} ì—…ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                    fail_path = DATA_DIR / f"failed_batch_exception_{batch_count}.jsonl"
                    print(f"âš  ì˜ˆì™¸ ë°œìƒ ë°°ì¹˜ ë¬¸ì„œë“¤ì„ {fail_path} ì— ì €ì¥í•©ë‹ˆë‹¤.")
                    with fail_path.open("w", encoding="utf-8") as f_fail:
                        # action/doc/action/doc êµ¬ì¡°ì—ì„œ doc ë¼ì¸ë§Œ ì €ì¥
                        for i in range(1, len(batch_actions), 2):
                            f_fail.write(batch_actions[i] + "\n")
                    raise  # ì™„ì „íˆ ë©ˆì¶”ê³  ì›ì¸ í™•ì¸í•  ìˆ˜ ìˆê²Œ

                if resp.get("errors"):
                    print(f"âš  ë°°ì¹˜ {batch_count}ì—ì„œ ì¼ë¶€ ë¬¸ì„œ ì˜¤ë¥˜ ë°œìƒ")
                    items = resp.get("items", [])
                    fail_path = DATA_DIR / f"failed_docs_batch_{batch_count}.jsonl"
                    with fail_path.open("w", encoding="utf-8") as f_fail:
                        for i, item in enumerate(items):
                            op, result = next(iter(item.items()))
                            if "error" in result:
                                err = result["error"]
                                # ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ì½˜ì†”ì— í‘œì‹œ
                                print(
                                    f"  - ë¬¸ì„œ #{i} ì‹¤íŒ¨: type={err.get('type')} "
                                    f"reason={err.get('reason')}"
                                )
                                # í•´ë‹¹ ë¬¸ì„œ ì›ë³¸(JSONL) ì €ì¥
                                doc_line_index = i * 2 + 1  # action/doc/action/doc...
                                if doc_line_index < len(batch_actions):
                                    f_fail.write(batch_actions[doc_line_index] + "\n")
                    print(f"âš  ì‹¤íŒ¨ ë¬¸ì„œë“¤ì€ {fail_path} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                batch_actions = []

        # ë‚¨ì€ ë¬¸ì„œ flush
        if batch_actions:
            batch_count += 1
            print(f"ğŸš€ ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_count} ì—…ë¡œë“œ ì¤‘... (ì´ {count}ê°œ ë¬¸ì„œ)")
            payload = "\n".join(batch_actions) + "\n"

            try:
                resp = client.transport.perform_request(
                    method="POST",
                    url=f"/{INDEX_NAME}/_bulk",
                    body=payload,
                    headers={"Content-Type": "application/json"}
                )
            except Exception as e:
                print(f"âŒ ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_count} ì—…ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                fail_path = DATA_DIR / f"failed_batch_exception_{batch_count}.jsonl"
                print(f"âš  ì˜ˆì™¸ ë°œìƒ ë°°ì¹˜ ë¬¸ì„œë“¤ì„ {fail_path} ì— ì €ì¥í•©ë‹ˆë‹¤.")
                with fail_path.open("w", encoding="utf-8") as f_fail:
                    for i in range(1, len(batch_actions), 2):
                        f_fail.write(batch_actions[i] + "\n")
                raise

            if resp.get("errors"):
                print(f"âš  ë§ˆì§€ë§‰ ë°°ì¹˜ {batch_count}ì—ì„œ ì¼ë¶€ ë¬¸ì„œ ì˜¤ë¥˜ ë°œìƒ")
                items = resp.get("items", [])
                fail_path = DATA_DIR / f"failed_docs_batch_{batch_count}.jsonl"
                with fail_path.open("w", encoding="utf-8") as f_fail:
                    for i, item in enumerate(items):
                        op, result = next(iter(item.items()))
                        if "error" in result:
                            err = result["error"]
                            print(
                                f"  - ë¬¸ì„œ #{i} ì‹¤íŒ¨: type={err.get('type')} "
                                f"reason={err.get('reason')}"
                            )
                            doc_line_index = i * 2 + 1
                            if doc_line_index < len(batch_actions):
                                f_fail.write(batch_actions[doc_line_index] + "\n")
                print(f"âš  ì‹¤íŒ¨ ë¬¸ì„œë“¤ì€ {fail_path} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print(f"âœ… ì „ì²´ ì—…ë¡œë“œ ì™„ë£Œ! ì´ {count}ê°œ ë¬¸ì„œ ì ì¬")


if __name__ == "__main__":
    bulk_ingest()
