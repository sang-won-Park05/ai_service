# ============================================
# 🔑 API Keys & Credentials (Sample Only)
# 실제 키는 .env 에 넣고 절대 공개하지 마세요
# ============================================

# ---------- OpenAI API ----------
OPENAI_API_KEY=your-openai-api-key

# 사용할 임베딩 모델 (기본: text-embedding-3-large)
EMBEDDING_MODEL=text-embedding-3-large

# 사용할 메인 LLM 모델 (예: gpt-4.1, gpt-4.1-mini, gpt-4o-mini 등)
LLM_MODEL=gpt-4o-mini


# ---------- OpenSearch ----------
OPENSEARCH_HOST=https://your-opensearch-endpoint.ap-northeast-2.aoss.amazonaws.com
OPENSEARCH_REGION=ap-northeast-2
OPENSEARCH_INDEX_NAME=medinote-index

# 벡터 필드명
OPENSEARCH_VECTOR_FIELD=embedding
OPENSEARCH_CONTENT_FIELD=content

# 벡터 차원 (OpenAI text-embedding-3-large = 3072)
EMBEDDING_DIM=3072


# ---------- AWS Credentials (OpenSearch Serverless) ----------
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key


# ============================================
# 📌 LangSmith / LangChain Observability
# ============================================

# LangSmith API Key (권장)
LANGSMITH_API_KEY=

# LangChain API Key (동일 키 — 호환성 위해 남겨둠)
LANGCHAIN_API_KEY=

# 프로젝트명 (기본: medinote)
LANGSMITH_PROJECT=medinote

# LangSmith Trace 활성화 (true/false)
LANGSMITH_TRACING=true

# 옵션: self-hosted LangSmith 서버 URL
LANGSMITH_ENDPOINT=


# ============================================
# 🎙️ Multimodal / STT / OCR
# ============================================

# Whisper small (로컬 STT) 사용시 → whisper-small
# OpenAI STT API 사용시 → gpt-4o-mini-transcribe
STT_MODEL=gpt-4o-mini-transcribe

# OCR 엔진: paddleocr 또는 gpt-vision
OCR_ENGINE=paddleocr


# ============================================
# ⚙️ General Settings
# ============================================

ENV=development
DEBUG=true
